# WolframTest
Evaluating different size neural networks to learn a square wave.

From my blog post (coming soon) https://aimlfun.com/lore-aint-lore-unless-you-use-rigour/

Stephen Wolfram wrote an excellent blog post about AI and ChatGPT https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/.

But when he suggested a 2 hidden neurons network could not learn a square wave graph, I wanted to try it out for myself and learn why, and answer the age old question, how many neurons should things require? He also seemed to suggest that it took a lot of epochs to train. This didn't sit comfortably with me. Again, this didn't quite seem right, and I wanted a platform to experiment for this simple example.

This application does precisely that. It tries different numbers of hidden nodes, and attempts to learn the graph.

Spoiler: 
(1) 2 hidden neurons absolutely can represent the graph 
(2) it doesn't talk very many epochs

Those two items are a minor thing in what was a superb and detail post from Stephen, and he remains someone I look up to. Please do read his post.
